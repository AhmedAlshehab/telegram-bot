import os
import io
import torch
import nest_asyncio
from telegram import Update
from telegram.ext import ApplicationBuilder, MessageHandler, filters, ContextTypes
from transformers import AutoModelForImageSegmentation
from torchvision import transforms
from PIL import Image
# --- Ø¥Ø¶Ø§ÙØ© Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø­Ù„ ---
from threading import Thread
from flask import Flask

# 1. ØªØ´ØºÙŠÙ„ Ø³ÙŠØ±ÙØ± ÙˆÙŠØ¨ ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ© Ù„Ø¥Ø±Ø¶Ø§Ø¡ Render
web_app = Flask('')
@web_app.route('/')
def home():
    return "Bot is Running Live!"

def run_web_server():
    port = int(os.environ.get('PORT', 10000))
    web_app.run(host='0.0.0.0', port=port)

# Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙŠØ±ÙØ± ÙÙŠ "Ø®ÙŠØ·" Ù…Ù†ÙØµÙ„ (Thread)
Thread(target=run_web_server).start()

# --- Ø¨Ù‚ÙŠØ© ÙƒÙˆØ¯Ùƒ Ø§Ù„Ø£ØµÙ„ÙŠ ÙƒÙ…Ø§ Ù‡Ùˆ ---
nest_asyncio.apply()

print("â³ Loading AI Model (BiRefNet)...")
device = "cuda" if torch.cuda.is_available() else "cpu"
model = AutoModelForImageSegmentation.from_pretrained("ZhengPeng7/BiRefNet", trust_remote_code=True)
model.to(device)
model.eval()

transform_image = transforms.Compose([
    transforms.Resize((1024, 1024)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

async def process_and_remove_bg(update: Update, context: ContextTypes.DEFAULT_TYPE):
    status_msg = await update.message.reply_text("â³ Ø¬Ø§Ø±ÙŠ ØªÙ†Ù‚ÙŠØ© Ø§Ù„ØµÙˆØ±Ø©... ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±")
    try:
        photo_file = await update.message.photo[-1].get_file()
        photo_bytes = await photo_file.download_as_bytearray()
        input_image = Image.open(io.BytesIO(photo_bytes)).convert("RGB")
        original_size = input_image.size

        input_tensor = transform_image(input_image).unsqueeze(0).to(device)
        if device == "cuda":
            input_tensor = input_tensor.to(model.dtype)

        with torch.no_grad():
            preds = model(input_tensor)[-1].sigmoid().cpu()
        
        mask = transforms.ToPILImage()(preds[0].float().squeeze())
        mask = mask.resize(original_size)
        input_image.putalpha(mask)
        
        out_io = io.BytesIO()
        input_image.save(out_io, 'PNG')
        out_io.seek(0)
        await update.message.reply_document(document=out_io, filename="no_bg.png", caption="âœ¨ ØªÙ… Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
    except Exception as e:
        await update.message.reply_text(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}")
    finally:
        await status_msg.delete()

if __name__ == '__main__':
    # ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¶Ø§ÙØ© BOT_TOKEN ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Render (Environment Variables)
    TOKEN = os.getenv("BOT_TOKEN") 
    if not TOKEN:
        print("âŒ Error: BOT_TOKEN not found!")
    else:
        app = ApplicationBuilder().token(TOKEN).build()
        app.add_handler(MessageHandler(filters.PHOTO, process_and_remove_bg))
        print("ğŸš€ Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†...")
        app.run_polling(close_loop=False)
        input_image = Image.open(io.BytesIO(photo_bytes)).convert("RGB")
        original_size = input_image.size

        # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        input_tensor = transform_image(input_image).unsqueeze(0).to(device)
        if device == "cuda":
            input_tensor = input_tensor.to(model.dtype)

        with torch.no_grad():
            preds = model(input_tensor)[-1].sigmoid().cpu()
        
        mask = transforms.ToPILImage()(preds[0].float().squeeze())
        mask = mask.resize(original_size)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø´ÙØ§ÙÙŠØ©
        input_image.putalpha(mask)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù„Ù…Ù„Ù Ù„Ø¥Ø±Ø³Ø§Ù„Ù‡
        out_io = io.BytesIO()
        input_image.save(out_io, 'PNG')
        out_io.seek(0)

        await update.message.reply_document(document=out_io, filename="no_bg.png", caption="âœ¨ ØªÙ… Ø§Ù„ØªØ®Ù„Øµ Ù…Ù† Ø§Ù„Ø®Ù„ÙÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!")
    except Exception as e:
        await update.message.reply_text(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {str(e)}")
    finally:
        await status_msg.delete()

# 3. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¨ÙˆØª
if __name__ == '__main__':
    TOKEN = os.getenv("BOT_TOKEN") # Ø³ÙŠØªÙ… Ø¬Ù„Ø¨Ù‡ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Render
    if not TOKEN:
        print("âŒ Error: BOT_TOKEN not found in environment variables!")
    else:
        app = ApplicationBuilder().token(TOKEN).build()
        app.add_handler(MessageHandler(filters.PHOTO, process_and_remove_bg))
        print("ğŸš€ Ø§Ù„Ø¨ÙˆØª ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†...")
        app.run_polling(close_loop=False)
